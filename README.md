**EspaÃ±ol:**

# ğŸ›’ Supermarket Inventory Optimizer (Batch Data Pipeline)

Proyecto de Data Engineering orientado a negocio y diseÃ±ado para optimizar el reabastecimiento de productos en supermercados regionales. Procesa datos histÃ³ricos de ventas, clima y promociones para generar recomendaciones logÃ­sticas automÃ¡ticas.

---

## ğŸš€ Objetivos

- Simular e ingestar datos multi-regionales de ventas diarias.
- Enriquecer con informaciÃ³n externa (clima, eventos).
- Validar y transformar datos con estÃ¡ndares empresariales.
- Orquestar un pipeline batch reproducible y escalable.
- Generar salidas limpias para consumo de BI, ciencia de datos o automatizaciÃ³n logÃ­stica.

---

## ğŸ“¦ Stack TecnolÃ³gico

| Componente           | Herramienta                     |
|----------------------|----------------------------------|
| OrquestaciÃ³n         | Apache Airflow / Perfect        |
| TransformaciÃ³n       | PySpark + pandas                 |
| SimulaciÃ³n           | Faker                            |
| Calidad de datos     | ydata-profiling + Great Expectations |
| Almacenamiento       | CSV (raw) â†’ Parquet / PostgreSQL |
| Entorno              | Poetry + VSCode + Jupyter        |
| Pruebas              | Pytest               |

---

## ğŸ“ Estructura del Proyecto

supermarket-inventory-optimizer/
â”œâ”€â”€ .vscode/ â† ConfiguraciÃ³n VSCode
â”œâ”€â”€ data/ â† Datos simulados (raw, processed)
â”œâ”€â”€ notebooks/ â† ExploraciÃ³n y anÃ¡lisis (EDA)
â”œâ”€â”€ scripts/ â† Scripts ejecutables
â”œâ”€â”€ dags/ â† DAGs de Perfect / Airflow
â”œâ”€â”€ src/ â† CÃ³digo fuente del pipeline
â”œâ”€â”€ tests/ â† Pruebas automÃ¡ticas
â”œâ”€â”€ pyproject.toml â† Dependencias gestionadas con Poetry
â”œâ”€â”€ README.md â† Este archivo

---

## ğŸ” Flujo General

1. **SimulaciÃ³n de datos:** Ventas regionales histÃ³ricas, promociones y clima.
2. **EDA y validaciÃ³n:** ExploraciÃ³n con `ydata-profiling`, reglas con `Great Expectations`.
3. **Ingesta:** Orquestada con Airflow o Prefect.
4. **TransformaciÃ³n:** Limpieza y normalizaciÃ³n con PySpark.
5. **Almacenamiento:** PostgreSQL o Parquet en `data/processed/`.
6. **Reportes / exportaciÃ³n:** Para dashboards o equipos de negocio.

---

## ğŸ“ˆ Ejemplo de resultados
- Reportes HTML automÃ¡ticos de EDA (ydata-profiling)

- Archivos processed/ optimizados y listos para analÃ­tica

- Reglas de validaciÃ³n con Great Expectations

- DAG funcional con mÃºltiples tareas interdependientes

---

## Autor

**Heberth Caripa**
Data Engineering & Machine Learning Enthusiast
ğŸ“ Chile | âœ‰ï¸ [heberthcaripa@gmail.com] | ğŸ”— [LinkedIn](https://www.linkedin.com/in/heberth-caripa/)

**English:** 

# ğŸ›’ Supermarket Inventory Optimizer (Batch Data Pipeline)

Business-oriented Data Engineering project designed to optimize product restocking in regional supermarkets. It processes historical sales, weather, and promotions data to generate automated logistics recommendations.

---

## ğŸš€ Objectives

- Simulate and ingest multi-regional daily sales data  
- Enrich with external sources (weather, events)  
- Validate and transform data with enterprise standards  
- Orchestrate a reproducible and scalable batch pipeline  
- Generate clean outputs for BI, data science, or logistics automation  

---

## ğŸ“¦ Tech Stack

| Component             | Tool                             |
|----------------------|----------------------------------|
| Orchestration         | Apache Airflow / Prefect        |
| Transformation        | PySpark + pandas                 |
| Simulation            | Faker                            |
| Data Quality          | ydata-profiling + Great Expectations |
| Storage               | CSV (raw) â†’ Parquet / PostgreSQL |
| Environment           | Poetry + VSCode + Jupyter        |
| Testing               | Pytest                           |

---

## ğŸ“ Project Structure

supermarket-inventory-optimizer/
â”œâ”€â”€ .vscode/ â† VSCode configuration
â”œâ”€â”€ data/ â† Simulated data (raw, processed)
â”œâ”€â”€ notebooks/ â† Exploration and analysis (EDA)
â”œâ”€â”€ scripts/ â† Executable scripts
â”œâ”€â”€ dags/ â† Perfect / Airflow DAGs
â”œâ”€â”€ src/ â† Pipeline source code
â”œâ”€â”€ tests/ â† Automated tests
â”œâ”€â”€ pyproject.toml â† Poetry-managed dependencies
â”œâ”€â”€ README.md â† This file


---

## ğŸ” General Flow

1. **Data Simulation:** Historical regional sales, promotions, and weather  
2. **EDA and Validation:** Exploration with `ydata-profiling`, rules with `Great Expectations`  
3. **Ingestion:** Orchestrated via Airflow or Prefect  
4. **Transformation:** Cleaning and normalization with PySpark  
5. **Storage:** PostgreSQL or Parquet in `data/processed/`  
6. **Reporting / Export:** For dashboards or business teams  

---

## ğŸ“ˆ Sample Outputs

- Automated HTML EDA reports (via ydata-profiling)  
- Optimized processed/ files ready for analytics  
- Validation rules with Great Expectations  
- Working DAG with interdependent tasks  

---

## Author

**Heberth Caripa**  
Data Engineering & Machine Learning Enthusiast  
ğŸ“ Chile | âœ‰ï¸ heberthcaripa@gmail.com | ğŸ”— [LinkedIn](https://www.linkedin.com/in/heberth-caripa/)
